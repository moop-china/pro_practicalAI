{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wKX2R_FT4hSQ",
    "mdEditEnable": false
   },
   "source": [
    "## 机器视觉\n",
    "\n",
    "\n",
    "<img src=\"data/logo.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "\n",
    "在这个课程项目中，我们会简单对用卷积神经网络实现的计算机视觉和相关知识进行介绍。虽然我们到现在都在使用CNN作文本处理，但是其实它最早还是用来完成计算机视觉任务的。\n",
    "\n",
    "\n",
    "<img src=\"data/cnn_cv.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zOUWqHjL6hmU",
    "mdEditEnable": false
   },
   "source": [
    "## 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vXjCadon6toa",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import Namespace\n",
    "import collections\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import re\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N518ySE16trp",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set Numpy and PyTorch seeds\n",
    "def set_seeds(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        \n",
    "# Creating directories\n",
    "def create_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PGQLzyss8wja",
    "mdEditEnable": false
   },
   "source": [
    "## 数据\n",
    "\n",
    "我们先来获取一些数据。一个常用的计算机视觉分类数据集是 [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html)。它包含了十种不同类型的图片数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NYy0WlkB9AoK",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 这里我们只是使用tf来下载数据\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Ka-WxeEJ8vAd",
    "outputId": "ec24e935-0562-4c55-c2ab-2bfe59a49128",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 495s 3us/step\n",
      "x: (60000, 32, 32, 3)\n",
      "y: (60000,)\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "X = np.vstack([x_train, x_test])\n",
    "y = np.vstack([y_train, y_test]).squeeze(1)\n",
    "print (\"x:\", X.shape)\n",
    "print (\"y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0YIiwLWcBH07",
    "mdEditEnable": false
   },
   "source": [
    "\n",
    "每张图片的长和宽都是32像素，和三个色彩通道(就是RGB), 我们将它存在一个文件夹里，每种类型的图片都有自己的文件夹，文件夹名就是对应图片的类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xWqzC-M1NCzx",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!rm -rf cifar10_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AdZjOciC-Bzm",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Classes\n",
    "classes = {0: 'plane', 1: 'car', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', \n",
    "           6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DbNtoIxD8dxc",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create image directories\n",
    "data_dir = \"cifar10_data\"\n",
    "os.mkdir(data_dir)\n",
    "for _class in classes.values():\n",
    "    os.mkdir(os.path.join(data_dir, _class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wf5EY4Ey8kFq",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save images for each class\n",
    "for i, (image, label) in enumerate(zip(X, y)):\n",
    "    _class = classes[label]\n",
    "    im = Image.fromarray(image)\n",
    "    im.save(os.path.join(data_dir, _class, \"{0:02d}.png\".format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "PrD2oUFu_KVF",
    "outputId": "e336f8c8-5cf5-4235-ec10-68761b6c725c",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some samples\n",
    "num_samples = len(classes)\n",
    "for i, _class in enumerate(classes.values()):  \n",
    "    for file in os.listdir(os.path.join(data_dir, _class)):\n",
    "        if file.endswith(\".png\"):\n",
    "            plt.subplot(1, num_samples, i+1)\n",
    "            plt.title(\"{0}\".format(_class))\n",
    "            img = Image.open(os.path.join(data_dir, _class, file))\n",
    "            plt.imshow(img)\n",
    "            plt.axis(\"off\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gVOkpS6O5b-B",
    "mdEditEnable": false
   },
   "source": [
    "## 分类\n",
    "\n",
    "任务是为给出的图片分类，我们会构建一个结构最基础的CNN然后用它处理数据，输出预测的分类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yLW2_1CG2Eyg",
    "mdEditEnable": false
   },
   "source": [
    "### 参数\n",
    "处理图片数据时，不需要保存切分后的文件，我们只会从文件夹中读取他们。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RTMvq5A849-w",
    "outputId": "f9142a73-fbf6-4504-f064-70417c6f8e6d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    seed=1234,\n",
    "    cuda=True,\n",
    "    shuffle=True,\n",
    "    data_dir=\"cifar10_data\",\n",
    "    vectorizer_file=\"vectorizer.json\",\n",
    "    model_state_file=\"model.pth\",\n",
    "    save_dir=\"cifar10_model\",\n",
    "    train_size=0.7,\n",
    "    val_size=0.15,\n",
    "    test_size=0.15,\n",
    "    num_epochs=10,\n",
    "    early_stopping_criteria=5,\n",
    "    learning_rate=1e-3,\n",
    "    batch_size=128,\n",
    "    num_filters=100,\n",
    "    hidden_dim=100,\n",
    "    dropout_p=0.1,\n",
    ")\n",
    "\n",
    "# Set seeds\n",
    "set_seeds(seed=args.seed, cuda=args.cuda)\n",
    "\n",
    "# Create save dir\n",
    "create_dirs(args.save_dir)\n",
    "\n",
    "# Expand filepaths\n",
    "args.vectorizer_file = os.path.join(args.save_dir, args.vectorizer_file)\n",
    "args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n",
    "\n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "print(\"Using CUDA: {}\".format(args.cuda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xaYCCEHOrpGB",
    "mdEditEnable": false
   },
   "source": [
    "### 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8iF6nxgDtOWk",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 将图片转换为Numpy Array\n",
    "def img_to_array(fp):\n",
    "    img = Image.open(fp)\n",
    "    array = np.asarray(img, dtype=\"float32\")\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3VlHdV9r5VzN",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "data = []\n",
    "for i, _class in enumerate(classes.values()):  \n",
    "    for file in os.listdir(os.path.join(data_dir, _class)):\n",
    "        if file.endswith(\".png\"):\n",
    "            full_filepath = os.path.join(data_dir, _class, file)\n",
    "            data.append({\"image\": img_to_array(full_filepath), \"category\": _class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "WvknlOjM5V1z",
    "outputId": "69e2f3bf-42df-4b08-b086-fc744e263db8",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 转化为 Dataframe\n",
    "df = pd.DataFrame(data)\n",
    "print (\"Image shape:\", df.image[0].shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "GXtRpahp5V6p",
    "outputId": "6ea08026-d651-4a75-d40f-94086fb211ce",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "by_category = collections.defaultdict(list)\n",
    "for _, row in df.iterrows():\n",
    "    by_category[row.category].append(row.to_dict())\n",
    "for category in by_category:\n",
    "    print (\"{0}: {1}\".format(category, len(by_category[category])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AYVNBhLgt-38",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_list = []\n",
    "for _, item_list in sorted(by_category.items()):\n",
    "    if args.shuffle:\n",
    "        np.random.shuffle(item_list)\n",
    "    n = len(item_list)\n",
    "    n_train = int(args.train_size*n)\n",
    "    n_val = int(args.val_size*n)\n",
    "    n_test = int(args.test_size*n)\n",
    "\n",
    "  # 给数据点一个切分属性\n",
    "    for item in item_list[:n_train]:\n",
    "        item['split'] = 'train'\n",
    "    for item in item_list[n_train:n_train+n_val]:\n",
    "        item['split'] = 'val'\n",
    "    for item in item_list[n_train+n_val:]:\n",
    "        item['split'] = 'test'  \n",
    "\n",
    "    # Add to final list\n",
    "    final_list.extend(item_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "o8GNPotNt-6X",
    "outputId": "162a2ddb-db83-4708-b48d-ecbf1d61dd4f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "split_df = pd.DataFrame(final_list)\n",
    "split_df[\"split\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cLdJQPBmX0yJ",
    "mdEditEnable": false
   },
   "source": [
    "### 词汇表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EB-kpxhct-_S",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    def __init__(self, token_to_idx=None):\n",
    "\n",
    "        # Token to index\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self.token_to_idx = token_to_idx\n",
    "\n",
    "        # Index to token\n",
    "        self.idx_to_token = {idx: token \\\n",
    "                             for token, idx in self.token_to_idx.items()}\n",
    "\n",
    "    def to_serializable(self):\n",
    "        return {'token_to_idx': self.token_to_idx}\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        return cls(**contents)\n",
    "\n",
    "    def add_token(self, token):\n",
    "        if token in self.token_to_idx:\n",
    "            index = self.token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self.token_to_idx)\n",
    "            self.token_to_idx[token] = index\n",
    "            self.idx_to_token[index] = token\n",
    "        return index\n",
    "\n",
    "    def add_tokens(self, tokens):\n",
    "        return [self.add_token[token] for token in tokens]\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        return self.token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        if index not in self.idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self.idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "QcpS2G28t_Bv",
    "outputId": "d0f38e9b-311a-42e1-a00a-ca75c8cf672e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Vocabulary(size=10)>\n",
      "10\n",
      "5\n",
      "dog\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary instance\n",
    "category_vocab = Vocabulary()\n",
    "for index, row in df.iterrows():\n",
    "    category_vocab.add_token(row.category)\n",
    "print (category_vocab) # __str__\n",
    "print (len(category_vocab)) # __len__\n",
    "index = category_vocab.lookup_token(\"dog\")\n",
    "print (index)\n",
    "print (category_vocab.lookup_index(index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ubECmrcqZIHI",
    "mdEditEnable": false
   },
   "source": [
    "### 序列化词汇表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "37pGFTBiZIbm",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvWL2JcgZPaw",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class SequenceVocabulary():\n",
    "    def __init__(self, train_means, train_stds):\n",
    "        \n",
    "        self.train_means = train_means\n",
    "        self.train_stds = train_stds\n",
    "        \n",
    "    def to_serializable(self):\n",
    "        contents = {'train_means': self.train_means,\n",
    "                    'train_stds': self.train_stds}\n",
    "        return contents\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, df):\n",
    "        train_data = df[df.split == \"train\"]\n",
    "        means = {0:[], 1:[], 2:[]}\n",
    "        stds = {0:[], 1:[], 2:[]}\n",
    "        for image in train_data.image:\n",
    "            for dim in range(3):\n",
    "                means[dim].append(np.mean(image[:, :, dim]))\n",
    "                stds[dim].append(np.std(image[:, :, dim]))\n",
    "        train_means = np.array((np.mean(means[0]), np.mean(means[1]), \n",
    "                                np.mean(means[2])), dtype=\"float64\").tolist()\n",
    "        train_stds = np.array((np.mean(stds[0]), np.mean(stds[1]), \n",
    "                               np.mean(stds[2])), dtype=\"float64\").tolist()\n",
    "            \n",
    "        return cls(train_means, train_stds)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"<SequenceVocabulary(train_means: {0}, train_stds: {1}>\".format(\n",
    "            self.train_means, self.train_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "-ODlh2wcahqH",
    "outputId": "b165d02a-3b92-40b8-92f5-5055533e6447",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SequenceVocabulary(train_means: [125.40174102783203, 122.99897766113281, 114.00146484375], train_stds: [51.5576171875, 50.800132751464844, 51.22932052612305]>\n"
     ]
    }
   ],
   "source": [
    "# Create SequenceVocabulary instance\n",
    "image_vocab = SequenceVocabulary.from_dataframe(split_df)\n",
    "print (image_vocab) # __str__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lUZKa0c9YD0V",
    "mdEditEnable": false
   },
   "source": [
    "### 向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RyxHZLTFX5VC",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class ImageVectorizer(object):\n",
    "    def __init__(self, image_vocab, category_vocab):\n",
    "        self.image_vocab = image_vocab\n",
    "        self.category_vocab = category_vocab\n",
    "\n",
    "    def vectorize(self, image):\n",
    "        \n",
    "        # Avoid modifying the actual df\n",
    "        image = np.copy(image)\n",
    "        \n",
    "        # Normalize\n",
    "        for dim in range(3):\n",
    "            mean = self.image_vocab.train_means[dim]\n",
    "            std = self.image_vocab.train_stds[dim]\n",
    "            image[:, :, dim] = ((image[:, :, dim] - mean) / std)\n",
    "            \n",
    "        # Reshape frok (32, 32, 3) to (3, 32, 32)\n",
    "        image = np.swapaxes(image, 0, 2)\n",
    "        image = np.swapaxes(image, 1, 2)\n",
    "                \n",
    "        return image\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, df):\n",
    "        \n",
    "        # Create class vocab\n",
    "        category_vocab = Vocabulary()   \n",
    "        for category in sorted(set(df.category)):\n",
    "            category_vocab.add_token(category)\n",
    "            \n",
    "        # Create image vocab\n",
    "        image_vocab = SequenceVocabulary.from_dataframe(df)\n",
    "        \n",
    "        return cls(image_vocab, category_vocab)\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        image_vocab = SequenceVocabulary.from_serializable(contents['image_vocab'])\n",
    "        category_vocab = Vocabulary.from_serializable(contents['category_vocab'])\n",
    "        return cls(image_vocab=image_vocab, \n",
    "                   category_vocab=category_vocab)\n",
    "    \n",
    "    def to_serializable(self):\n",
    "        return {'image_vocab': self.image_vocab.to_serializable(),\n",
    "                'category_vocab': self.category_vocab.to_serializable()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "yXWIhtFUiDUe",
    "outputId": "62f2c017-da89-4333-8cd3-f84abe05723b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SequenceVocabulary(train_means: [125.40174102783203, 122.99897766113281, 114.00146484375], train_stds: [51.5576171875, 50.800132751464844, 51.22932052612305]>\n",
      "<Vocabulary(size=10)>\n",
      "(3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# Vectorizer instance\n",
    "vectorizer = ImageVectorizer.from_dataframe(split_df)\n",
    "print (vectorizer.image_vocab)\n",
    "print (vectorizer.category_vocab)\n",
    "image_vector = vectorizer.vectorize(split_df.iloc[0].image)\n",
    "print (image_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xm7s9RPThF3c",
    "mdEditEnable": false
   },
   "source": [
    "### 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2mL4eEdNX5c1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dzegh16nX5fY",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, vectorizer):\n",
    "        self.df = df\n",
    "        self.vectorizer = vectorizer\n",
    "\n",
    "        # Data splits\n",
    "        self.train_df = self.df[self.df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "        self.val_df = self.df[self.df.split=='val']\n",
    "        self.val_size = len(self.val_df)\n",
    "        self.test_df = self.df[self.df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "        self.lookup_dict = {'train': (self.train_df, self.train_size), \n",
    "                            'val': (self.val_df, self.val_size),\n",
    "                            'test': (self.test_df, self.test_size)}\n",
    "        self.set_split('train')\n",
    "\n",
    "        # Class weights (for imbalances)\n",
    "        class_counts = df.category.value_counts().to_dict()\n",
    "        def sort_key(item):\n",
    "            return self.vectorizer.category_vocab.lookup_token(item[0])\n",
    "        sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
    "        frequencies = [count for _, count in sorted_counts]\n",
    "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, df):\n",
    "        train_df = df[df.split=='train']\n",
    "        return cls(df, ImageVectorizer.from_dataframe(train_df))\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls, df, vectorizer_filepath):\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(df, vectorizer)\n",
    "\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        with open(vectorizer_filepath) as fp:\n",
    "            return ImageVectorizer.from_serializable(json.load(fp))\n",
    "\n",
    "    def save_vectorizer(self, vectorizer_filepath):\n",
    "        with open(vectorizer_filepath, \"w\") as fp:\n",
    "            json.dump(self.vectorizer.to_serializable(), fp)\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        self.target_split = split\n",
    "        self.target_df, self.target_size = self.lookup_dict[split]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Dataset(split={0}, size={1})\".format(\n",
    "            self.target_split, self.target_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.target_df.iloc[index]\n",
    "        image_vector = self.vectorizer.vectorize(row.image)\n",
    "        category_index = self.vectorizer.category_vocab.lookup_token(row.category)\n",
    "        return {'image': image_vector, \n",
    "                'category': category_index}\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        return len(self) // batch_size\n",
    "\n",
    "    def generate_batches(self, batch_size, shuffle=True, drop_last=True, device=\"cpu\"):\n",
    "        dataloader = DataLoader(dataset=self, batch_size=batch_size, \n",
    "                                shuffle=shuffle, drop_last=drop_last)\n",
    "        for data_dict in dataloader:\n",
    "            out_data_dict = {}\n",
    "            for name, tensor in data_dict.items():\n",
    "                out_data_dict[name] = data_dict[name].to(device)\n",
    "            yield out_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "-sW6otUGX5iA",
    "outputId": "5abb9822-37dd-4680-ba93-f85f79c77296",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Dataset(split=train, size=42000)\n",
      "(3, 32, 32)\n",
      "bird\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002])\n"
     ]
    }
   ],
   "source": [
    "# Dataset instance\n",
    "dataset = ImageDataset.load_dataset_and_make_vectorizer(split_df)\n",
    "print (dataset) # __str__\n",
    "input_ = dataset[10] # __getitem__\n",
    "print (input_['image'].shape)\n",
    "category = input_['category']\n",
    "print (dataset.vectorizer.category_vocab.lookup_index(category))\n",
    "print (dataset.class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SjPHp36i3G_i",
    "mdEditEnable": false
   },
   "source": [
    "### 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bPaf6Dy2X5ko",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RKRPzX1nX5nN",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class ImageModel(nn.Module):\n",
    "    def __init__(self, num_hidden_units, num_classes, dropout_p):\n",
    "        super(ImageModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5) # input_channels:3 , output_channels:10 (aka num filters)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) \n",
    "        self.conv_dropout = nn.Dropout2d(dropout_p)\n",
    "        self.fc1 = nn.Linear(20*5*5, num_hidden_units)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc2 = nn.Linear(num_hidden_units, num_classes)\n",
    "\n",
    "    def forward(self, x, apply_softmax=False):\n",
    "          \n",
    "        # 卷积层和池化\n",
    "        z = self.conv1(x) # (N, 10, 28, 28)\n",
    "        z = F.max_pool2d(z, 2) # (N, 10, 14, 14)\n",
    "        z = F.relu(z)\n",
    "        \n",
    "        # 卷积层和池化\n",
    "        z = self.conv2(z) # (N, 20, 10, 10)\n",
    "        z = self.conv_dropout(z) \n",
    "        z = F.max_pool2d(z, 2) # (N, 20, 5, 5)\n",
    "        z = F.relu(z)\n",
    "        \n",
    "        # 整平操作\n",
    "        z = z.view(-1, 20*5*5)\n",
    "        \n",
    "        # 全连接层\n",
    "        z = F.relu(self.fc1(z))\n",
    "        z = self.dropout(z)\n",
    "        y_pred = self.fc2(z)\n",
    "        \n",
    "        if apply_softmax:\n",
    "            y_pred = F.softmax(y_pred, dim=1)\n",
    "        return y_pred \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jAiIbY9TBGef",
    "mdEditEnable": false
   },
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bnMvjt9JX5p4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o0bR1rzqX5sg",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, dataset, model, model_state_file, save_dir, device, \n",
    "                 shuffle, num_epochs, batch_size, learning_rate, \n",
    "                 early_stopping_criteria):\n",
    "        self.dataset = dataset\n",
    "        self.class_weights = dataset.class_weights.to(device)\n",
    "        self.device = device\n",
    "        self.model = model.to(device)\n",
    "        self.save_dir = save_dir\n",
    "        self.device = device\n",
    "        self.shuffle = shuffle\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.loss_func = nn.CrossEntropyLoss(self.class_weights)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer=self.optimizer, mode='min', factor=0.5, patience=1)\n",
    "        self.train_state = {\n",
    "            'stop_early': False, \n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'early_stopping_criteria': early_stopping_criteria,\n",
    "            'learning_rate': learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': model_state_file}\n",
    "    \n",
    "    def update_train_state(self):\n",
    "\n",
    "        # Verbose\n",
    "        print (\"[EPOCH]: {0:02d} | [LR]: {1} | [TRAIN LOSS]: {2:.2f} | [TRAIN ACC]: {3:.1f}% | [VAL LOSS]: {4:.2f} | [VAL ACC]: {5:.1f}%\".format(\n",
    "          self.train_state['epoch_index'], self.train_state['learning_rate'], \n",
    "            self.train_state['train_loss'][-1], self.train_state['train_acc'][-1], \n",
    "            self.train_state['val_loss'][-1], self.train_state['val_acc'][-1]))\n",
    "\n",
    "        # Save one model at least\n",
    "        if self.train_state['epoch_index'] == 0:\n",
    "            torch.save(self.model.state_dict(), self.train_state['model_filename'])\n",
    "            self.train_state['stop_early'] = False\n",
    "\n",
    "        # Save model if performance improved\n",
    "        elif self.train_state['epoch_index'] >= 1:\n",
    "            loss_tm1, loss_t = self.train_state['val_loss'][-2:]\n",
    "\n",
    "            # If loss worsened\n",
    "            if loss_t >= self.train_state['early_stopping_best_val']:\n",
    "                # Update step\n",
    "                self.train_state['early_stopping_step'] += 1\n",
    "\n",
    "            # Loss decreased\n",
    "            else:\n",
    "                # Save the best model\n",
    "                if loss_t < self.train_state['early_stopping_best_val']:\n",
    "                    torch.save(self.model.state_dict(), self.train_state['model_filename'])\n",
    "\n",
    "                # Reset early stopping step\n",
    "                self.train_state['early_stopping_step'] = 0\n",
    "\n",
    "            # Stop early ?\n",
    "            self.train_state['stop_early'] = self.train_state['early_stopping_step'] \\\n",
    "              >= self.train_state['early_stopping_criteria']\n",
    "        return self.train_state\n",
    "  \n",
    "    def compute_accuracy(self, y_pred, y_target):\n",
    "        _, y_pred_indices = y_pred.max(dim=1)\n",
    "        n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "        return n_correct / len(y_pred_indices) * 100\n",
    "  \n",
    "    def run_train_loop(self):\n",
    "        for epoch_index in range(self.num_epochs):\n",
    "            self.train_state['epoch_index'] = epoch_index\n",
    "      \n",
    "            # Iterate over train dataset\n",
    "\n",
    "            # initialize batch generator, set loss and acc to 0, set train mode on\n",
    "            self.dataset.set_split('train')\n",
    "            batch_generator = self.dataset.generate_batches(\n",
    "                batch_size=self.batch_size, shuffle=self.shuffle, \n",
    "                device=self.device)\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "            self.model.train()\n",
    "\n",
    "            for batch_index, batch_dict in enumerate(batch_generator):\n",
    "                # zero the gradients\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                # compute the output\n",
    "                y_pred = self.model(x=batch_dict['image'])\n",
    "                \n",
    "                # compute the loss\n",
    "                loss = self.loss_func(y_pred, batch_dict['category'])\n",
    "                loss_t = loss.item()\n",
    "                running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "                # compute gradients using loss\n",
    "                loss.backward()\n",
    "\n",
    "                # use optimizer to take a gradient step\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                # compute the accuracy\n",
    "                acc_t = self.compute_accuracy(y_pred, batch_dict['category'])\n",
    "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            self.train_state['train_loss'].append(running_loss)\n",
    "            self.train_state['train_acc'].append(running_acc)\n",
    "\n",
    "            # Iterate over val dataset\n",
    "\n",
    "            # initialize batch generator, set loss and acc to 0, set eval mode on\n",
    "            self.dataset.set_split('val')\n",
    "            batch_generator = self.dataset.generate_batches(\n",
    "                batch_size=self.batch_size, shuffle=self.shuffle, device=self.device)\n",
    "            running_loss = 0.\n",
    "            running_acc = 0.\n",
    "            self.model.eval()\n",
    "\n",
    "            for batch_index, batch_dict in enumerate(batch_generator):\n",
    "\n",
    "                # compute the output\n",
    "                y_pred = self.model(x=batch_dict['image'])\n",
    "\n",
    "                # compute the loss\n",
    "                loss = self.loss_func(y_pred, batch_dict['category'])\n",
    "                loss_t = loss.to(\"cpu\").item()\n",
    "                running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "                # compute the accuracy\n",
    "                acc_t = self.compute_accuracy(y_pred, batch_dict['category'])\n",
    "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            self.train_state['val_loss'].append(running_loss)\n",
    "            self.train_state['val_acc'].append(running_acc)\n",
    "\n",
    "            self.train_state = self.update_train_state()\n",
    "            self.scheduler.step(self.train_state['val_loss'][-1])\n",
    "            if self.train_state['stop_early']:\n",
    "                break\n",
    "          \n",
    "    def run_test_loop(self):\n",
    "        # initialize batch generator, set loss and acc to 0, set eval mode on\n",
    "        self.dataset.set_split('test')\n",
    "        batch_generator = self.dataset.generate_batches(\n",
    "            batch_size=self.batch_size, shuffle=self.shuffle, device=self.device)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        self.model.eval()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # compute the output\n",
    "            y_pred = self.model(x=batch_dict['image'])\n",
    "\n",
    "            # compute the loss\n",
    "            loss = self.loss_func(y_pred, batch_dict['category'])\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # compute the accuracy\n",
    "            acc_t = self.compute_accuracy(y_pred, batch_dict['category'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "        self.train_state['test_loss'] = running_loss\n",
    "        self.train_state['test_acc'] = running_acc\n",
    "    \n",
    "    def plot_performance(self):\n",
    "        # Figure size\n",
    "        plt.figure(figsize=(15,5))\n",
    "\n",
    "        # Plot Loss\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(\"Loss\")\n",
    "        plt.plot(trainer.train_state[\"train_loss\"], label=\"train\")\n",
    "        plt.plot(trainer.train_state[\"val_loss\"], label=\"val\")\n",
    "        plt.legend(loc='upper right')\n",
    "\n",
    "        # Plot Accuracy\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(\"Accuracy\")\n",
    "        plt.plot(trainer.train_state[\"train_acc\"], label=\"train\")\n",
    "        plt.plot(trainer.train_state[\"val_acc\"], label=\"val\")\n",
    "        plt.legend(loc='lower right')\n",
    "\n",
    "        # Save figure\n",
    "        plt.savefig(os.path.join(self.save_dir, \"performance.png\"))\n",
    "\n",
    "        # Show plots\n",
    "        plt.show()\n",
    "    \n",
    "    def save_train_state(self):\n",
    "        with open(os.path.join(self.save_dir, \"train_state.json\"), \"w\") as fp:\n",
    "            json.dump(self.train_state, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "Ug60AELzX5vT",
    "outputId": "74f5b9db-ebc0-47d5-e496-afabe9c0ca7b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_modules of ImageModel(\n",
      "  (conv1): Conv2d(3, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv_dropout): Dropout2d(p=0.1)\n",
      "  (fc1): Linear(in_features=500, out_features=100, bias=True)\n",
      "  (dropout): Dropout(p=0.1)\n",
      "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "dataset = ImageDataset.load_dataset_and_make_vectorizer(split_df)\n",
    "dataset.save_vectorizer(args.vectorizer_file)\n",
    "vectorizer = dataset.vectorizer\n",
    "model = ImageModel(num_hidden_units=args.hidden_dim, \n",
    "                   num_classes=len(vectorizer.category_vocab),\n",
    "                   dropout_p=args.dropout_p)\n",
    "print (model.named_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vF9kAEXEX5a4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH]: 00 | [LR]: 0.001 | [TRAIN LOSS]: 1.69 | [TRAIN ACC]: 38.6% | [VAL LOSS]: 1.47 | [VAL ACC]: 47.0%\n",
      "[EPOCH]: 01 | [LR]: 0.001 | [TRAIN LOSS]: 1.39 | [TRAIN ACC]: 50.1% | [VAL LOSS]: 1.29 | [VAL ACC]: 53.9%\n",
      "[EPOCH]: 02 | [LR]: 0.001 | [TRAIN LOSS]: 1.27 | [TRAIN ACC]: 54.9% | [VAL LOSS]: 1.19 | [VAL ACC]: 57.3%\n",
      "[EPOCH]: 03 | [LR]: 0.001 | [TRAIN LOSS]: 1.19 | [TRAIN ACC]: 57.7% | [VAL LOSS]: 1.13 | [VAL ACC]: 60.7%\n",
      "[EPOCH]: 04 | [LR]: 0.001 | [TRAIN LOSS]: 1.13 | [TRAIN ACC]: 60.0% | [VAL LOSS]: 1.11 | [VAL ACC]: 61.2%\n",
      "[EPOCH]: 05 | [LR]: 0.001 | [TRAIN LOSS]: 1.08 | [TRAIN ACC]: 61.6% | [VAL LOSS]: 1.07 | [VAL ACC]: 62.5%\n",
      "[EPOCH]: 06 | [LR]: 0.001 | [TRAIN LOSS]: 1.04 | [TRAIN ACC]: 63.2% | [VAL LOSS]: 1.06 | [VAL ACC]: 62.3%\n",
      "[EPOCH]: 07 | [LR]: 0.001 | [TRAIN LOSS]: 1.02 | [TRAIN ACC]: 64.2% | [VAL LOSS]: 1.02 | [VAL ACC]: 63.8%\n",
      "[EPOCH]: 08 | [LR]: 0.001 | [TRAIN LOSS]: 0.99 | [TRAIN ACC]: 65.5% | [VAL LOSS]: 1.01 | [VAL ACC]: 64.6%\n",
      "[EPOCH]: 09 | [LR]: 0.001 | [TRAIN LOSS]: 0.96 | [TRAIN ACC]: 66.3% | [VAL LOSS]: 0.99 | [VAL ACC]: 65.4%\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "trainer = Trainer(dataset=dataset, model=model, \n",
    "                  model_state_file=args.model_state_file, \n",
    "                  save_dir=args.save_dir, device=args.device,\n",
    "                  shuffle=args.shuffle, num_epochs=args.num_epochs, \n",
    "                  batch_size=args.batch_size, learning_rate=args.learning_rate, \n",
    "                  early_stopping_criteria=args.early_stopping_criteria)\n",
    "trainer.run_train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "colab_type": "code",
    "id": "2G6I5YWtt_Ea",
    "outputId": "0ca459c6-0053-4a43-82a3-6a1e1c6e5c33",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5f08a7870ff3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot performance\n",
    "trainer.plot_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Iz3G5eaTS04m",
    "outputId": "9d3a0b4e-59d3-4fcd-860f-f0a062c4e8e9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.98\n",
      "Test Accuracy: 66.3%\n"
     ]
    }
   ],
   "source": [
    "# Test performance\n",
    "trainer.run_test_loop()\n",
    "print(\"Test loss: {0:.2f}\".format(trainer.train_state['test_loss']))\n",
    "print(\"Test Accuracy: {0:.1f}%\".format(trainer.train_state['test_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kqMzljfpS09F",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save all results\n",
    "trainer.save_train_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1fMNOVJUYvhs",
    "mdEditEnable": false
   },
   "source": [
    "\n",
    "66% 左右的测试性能在 Cifar10 数据集上并不差，但是我们可以做的更好。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EclYytw6Swh-",
    "mdEditEnable": false
   },
   "source": [
    "## Transfer learning\n",
    "## 迁移学习\n",
    "\n",
    "这一节里，我们即将使用在很多数据集上的性能都非常好的训练好的模型。我们会直接使用它的构架和权重来初始化模型，并用它训练。我们就冻结初始的卷积权重，然后调整后面的卷积和全连接层。\n",
    " \n",
    "迁移学习之所以适用于这个场景，是因为最初的卷积层在处理图片中包含(不管他的类别是什么)的空间信息时表现十分优异。我们会用这些巨大的已训练好模型的特征提取器用在自己的数据集上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mxl4PEfqTMwm",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "GjufXPDJTB7W",
    "outputId": "709a1c26-7c67-420f-83be-bdf5409cf4cc",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alexnet', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'inception_v3', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn']\n"
     ]
    }
   ],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "print (model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1173
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "daJN4BSWS016",
    "outputId": "0608949f-b8ec-471e-c32b-04079b8980b9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\" to /home/kesci/.torch/models/vgg19_bn-c79401a0.pth\n",
      "100%|██████████| 574769405/574769405 [00:42<00:00, 13614017.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_parameters of VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace)\n",
      "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (25): ReLU(inplace)\n",
      "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace)\n",
      "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): ReLU(inplace)\n",
      "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): ReLU(inplace)\n",
      "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace)\n",
      "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (45): ReLU(inplace)\n",
      "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (48): ReLU(inplace)\n",
      "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (51): ReLU(inplace)\n",
      "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "model_name = 'vgg19_bn'\n",
    "vgg_19bn = models.__dict__[model_name](pretrained=True) # Set false to train from scratch\n",
    "print (vgg_19bn.named_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XBudDGFz1j87",
    "mdEditEnable": false
   },
   "source": [
    "我们选择的 VGG模型 包含了 特征--`features` 和 分类器--`classifier`两个组件。`features`组件由卷积层和池化层组成，作为特征提取器。而 `classifier`组件由全连接层组成。我们将会冻结 `feature`组件绝大多的权重，然后为了CIFAR10分类任务自己设计全连接层。如果你想直接使用VGG而不是稍作修改，你可以在本地的 `/usr/local/lib/python3.X/dist-packages/torchvision/models` 访问默认的模型。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YmzQIXsd59Rj",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class ImageModel(nn.Module):\n",
    "    def __init__(self, feature_extractor, num_hidden_units, \n",
    "                 num_classes, dropout_p):\n",
    "        super(ImageModel, self).__init__()\n",
    "        \n",
    "        # 训练好的特征提取器\n",
    "        self.feature_extractor = feature_extractor\n",
    "        \n",
    "        # 全连接层权重\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 250, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(250, 100, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(100, 10, bias=True),\n",
    "            )\n",
    "\n",
    "    def forward(self, x, apply_softmax=False):\n",
    "          \n",
    "        # 特征提取器\n",
    "        z = self.feature_extractor(x)\n",
    "        z = z.view(x.size(0), -1)\n",
    "        \n",
    "        # FC\n",
    "        y_pred = self.classifier(z)\n",
    "\n",
    "        if apply_softmax:\n",
    "            y_pred = F.softmax(y_pred, dim=1)\n",
    "        return y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1139
    },
    "colab_type": "code",
    "id": "czo1bGBwXKNj",
    "outputId": "9d407e14-2415-41ba-9f20-37e33f8ab716",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_parameters of ImageModel(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace)\n",
      "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (25): ReLU(inplace)\n",
      "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace)\n",
      "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): ReLU(inplace)\n",
      "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): ReLU(inplace)\n",
      "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace)\n",
      "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (45): ReLU(inplace)\n",
      "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (48): ReLU(inplace)\n",
      "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (51): ReLU(inplace)\n",
      "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=250, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=250, out_features=100, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "dataset = ImageDataset.load_dataset_and_make_vectorizer(split_df)\n",
    "dataset.save_vectorizer(args.vectorizer_file)\n",
    "vectorizer = dataset.vectorizer\n",
    "model = ImageModel(feature_extractor=vgg_19bn.features, \n",
    "                   num_hidden_units=args.hidden_dim,\n",
    "                   num_classes=len(vectorizer.category_vocab), \n",
    "                   dropout_p=args.dropout_p)\n",
    "print (model.named_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hZybxGHoDTwQ",
    "mdEditEnable": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 微调最后几层卷积层和全连接层\n",
    "for i, param in enumerate(model.feature_extractor.parameters()):\n",
    "    if i < 36:\n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GTbYKussTvB2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH]: 00 | [LR]: 0.001 | [TRAIN LOSS]: 0.93 | [TRAIN ACC]: 71.7% | [VAL LOSS]: 0.60 | [VAL ACC]: 80.9%\n",
      "[EPOCH]: 01 | [LR]: 0.001 | [TRAIN LOSS]: 0.57 | [TRAIN ACC]: 83.1% | [VAL LOSS]: 0.55 | [VAL ACC]: 83.3%\n",
      "[EPOCH]: 02 | [LR]: 0.001 | [TRAIN LOSS]: 0.42 | [TRAIN ACC]: 87.7% | [VAL LOSS]: 0.55 | [VAL ACC]: 84.0%\n",
      "[EPOCH]: 03 | [LR]: 0.001 | [TRAIN LOSS]: 0.33 | [TRAIN ACC]: 90.5% | [VAL LOSS]: 0.54 | [VAL ACC]: 84.7%\n",
      "[EPOCH]: 04 | [LR]: 0.001 | [TRAIN LOSS]: 0.26 | [TRAIN ACC]: 92.7% | [VAL LOSS]: 0.53 | [VAL ACC]: 84.7%\n",
      "[EPOCH]: 05 | [LR]: 0.001 | [TRAIN LOSS]: 0.19 | [TRAIN ACC]: 94.7% | [VAL LOSS]: 0.58 | [VAL ACC]: 85.0%\n",
      "[EPOCH]: 06 | [LR]: 0.001 | [TRAIN LOSS]: 0.15 | [TRAIN ACC]: 95.8% | [VAL LOSS]: 0.64 | [VAL ACC]: 85.1%\n",
      "[EPOCH]: 07 | [LR]: 0.001 | [TRAIN LOSS]: 0.08 | [TRAIN ACC]: 97.9% | [VAL LOSS]: 0.60 | [VAL ACC]: 86.6%\n",
      "[EPOCH]: 08 | [LR]: 0.001 | [TRAIN LOSS]: 0.04 | [TRAIN ACC]: 98.9% | [VAL LOSS]: 0.72 | [VAL ACC]: 86.5%\n",
      "[EPOCH]: 09 | [LR]: 0.001 | [TRAIN LOSS]: 0.03 | [TRAIN ACC]: 99.3% | [VAL LOSS]: 0.72 | [VAL ACC]: 87.4%\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "trainer = Trainer(dataset=dataset, model=model, \n",
    "                  model_state_file=args.model_state_file, \n",
    "                  save_dir=args.save_dir, device=args.device,\n",
    "                  shuffle=args.shuffle, num_epochs=args.num_epochs, \n",
    "                  batch_size=args.batch_size, learning_rate=args.learning_rate, \n",
    "                  early_stopping_criteria=args.early_stopping_criteria)\n",
    "trainer.run_train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "colab_type": "code",
    "id": "NCLCnQgATvMj",
    "outputId": "20bca437-868c-41c3-c95c-4b328c9024fc",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.kesci.com/rt_upload/NCLCnQgATvMj/pk9v2jlvp3.png\">"
      ],
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot performance\n",
    "trainer.plot_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Hjn0HJVoTvJ0",
    "outputId": "789735eb-61fc-4745-e133-c161f9d6fec9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.72\n",
      "Test Accuracy: 87.2%\n"
     ]
    }
   ],
   "source": [
    "# Test performance\n",
    "trainer.run_test_loop()\n",
    "print(\"Test loss: {0:.2f}\".format(trainer.train_state['test_loss']))\n",
    "print(\"Test Accuracy: {0:.1f}%\".format(trainer.train_state['test_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZQVrGTNNTvH0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save all results\n",
    "trainer.save_train_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7CL689FebJhf",
    "mdEditEnable": false
   },
   "source": [
    "性能好了太多了！如果训练时间足够的话，最高可以达到 95% 的准确率 :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "02iDXCtiYo5K",
    "mdEditEnable": false
   },
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cVT--tAvnOu7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 1, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1qQjnXpnYoMM",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Inference(object):\n",
    "    def __init__(self, model, vectorizer):\n",
    "        self.model = model\n",
    "        self.model.to(\"cpu\")\n",
    "        self.vectorizer = vectorizer\n",
    "  \n",
    "    def predict_category(self, image):\n",
    "        # Vectorize\n",
    "        image_vector = self.vectorizer.vectorize(image)\n",
    "        image_vector = torch.tensor(image_vector).unsqueeze(0)\n",
    "        \n",
    "        # Forward pass\n",
    "        self.model.eval()\n",
    "        y_pred = self.model(x=image_vector, apply_softmax=True)\n",
    "\n",
    "        # Top category\n",
    "        y_prob, indices = y_pred.max(dim=1)\n",
    "        index = indices.item()\n",
    "\n",
    "        # Predicted category\n",
    "        category = vectorizer.category_vocab.lookup_index(index)\n",
    "        probability = y_prob.item()\n",
    "        return {'category': category, 'probability': probability}\n",
    "    \n",
    "    def predict_top_k(self, image, k):\n",
    "        # Vectorize\n",
    "        image_vector = self.vectorizer.vectorize(image)\n",
    "        image_vector = torch.tensor(image_vector).unsqueeze(0)\n",
    "        \n",
    "        # Forward pass\n",
    "        self.model.eval()\n",
    "        y_pred = self.model(x=image_vector, apply_softmax=True)\n",
    "        \n",
    "        # Top k categories\n",
    "        y_prob, indices = torch.topk(y_pred, k=k)\n",
    "        probabilities = y_prob.detach().numpy()[0]\n",
    "        indices = indices.detach().numpy()[0]\n",
    "\n",
    "        # Results\n",
    "        results = []\n",
    "        for probability, index in zip(probabilities, indices):\n",
    "            category = self.vectorizer.category_vocab.lookup_index(index)\n",
    "            results.append({'category': category, 'probability': probability})\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MbTRzW8CYoWc",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f514575e50e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get a sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'split_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Get a sample\n",
    "sample = split_df[split_df.split==\"test\"].iloc[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "DswQ0pikYoR_",
    "outputId": "dedeef0c-be8e-4015-b401-7bb57080a641",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: car\n",
      "(car → p=1.00)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.kesci.com/rt_upload/DswQ0pikYoR_/pk9w20dzat.png\">"
      ],
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inference\n",
    "inference = Inference(model=model, vectorizer=vectorizer)\n",
    "prediction = inference.predict_category(sample.image)\n",
    "print (\"Actual:\", sample.category)\n",
    "test_image = np.array(sample.image, dtype='uint8')\n",
    "plt.imshow(test_image)\n",
    "plt.axis(\"off\")\n",
    "print(\"({} → p={:0.2f})\".format(prediction['category'], \n",
    "                                prediction['probability']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "72_-iRQxYoQK",
    "outputId": "7a65b46b-fc51-4b24-eba1-d2a404af6e91",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: car\n",
      "car → (p=1.00)\n",
      "truck → (p=0.00)\n",
      "ship → (p=0.00)\n",
      "plane → (p=0.00)\n",
      "frog → (p=0.00)\n",
      "dog → (p=0.00)\n",
      "cat → (p=0.00)\n",
      "bird → (p=0.00)\n",
      "deer → (p=0.00)\n",
      "horse → (p=0.00)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.kesci.com/rt_upload/72_-iRQxYoQK/pk9w2gbl3o.png\">"
      ],
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Top-k inference\n",
    "top_k = inference.predict_top_k(sample.image, k=len(vectorizer.category_vocab))\n",
    "print (\"Actual:\", sample.category)\n",
    "plt.imshow(test_image)\n",
    "plt.axis(\"off\")\n",
    "for result in top_k:\n",
    "    print (\"{} → (p={:0.2f})\".format(result['category'], \n",
    "                                     result['probability']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CFD1E5865019468F8ED5A055B1461D2C"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
