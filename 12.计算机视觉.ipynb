{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wKX2R_FT4hSQ",
    "mdEditEnable": false
   },
   "source": [
    "## 机器视觉\n",
    "\n",
    "\n",
    "<img src=\"data/logo.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "\n",
    "在这个课程项目中，我们会简单对用卷积神经网络实现的计算机视觉和相关知识进行介绍。虽然我们到现在都在使用CNN作文本处理，但是其实它最早还是用来完成计算机视觉任务的。\n",
    "\n",
    "\n",
    "<img src=\"data/cnn_cv.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zOUWqHjL6hmU",
    "mdEditEnable": false
   },
   "source": [
    "## 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "kjXAaAyx6i5W",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting torch\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/86/78/a113ef4e76dfb539e5c73be2aa010008b88fe1d83e324b5a3b16011bb245/torch-1.0.0-cp35-cp35m-manylinux1_x86_64.whl (591.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 591.8MB 71kB/s \n",
      "\u001b[?25hRequirement already up-to-date: torchvision in /opt/conda/lib/python3.5/site-packages (0.2.1)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /opt/conda/lib/python3.5/site-packages (from torchvision) (4.2.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/lib/python3.5/site-packages (from torchvision) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /opt/conda/lib/python3.5/site-packages (from torchvision) (1.14.2)\n",
      "Requirement already satisfied, skipping upgrade: olefile in /opt/conda/lib/python3.5/site-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
      "Installing collected packages: torch\n",
      "  Found existing installation: torch 0.4.0\n",
      "    Uninstalling torch-0.4.0:\n",
      "      Successfully uninstalled torch-0.4.0\n",
      "Successfully installed torch-1.0.0\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting Pillow==4.1.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/17/fadfc92ffa5db9da7b0d902d72972a16b807b51219f4017f45899d0a5f7c/Pillow-4.1.1-cp35-cp35m-manylinux1_x86_64.whl (5.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.7MB 511kB/s \n",
      "\u001b[?25hRequirement already satisfied: olefile in /opt/conda/lib/python3.5/site-packages (from Pillow==4.1.1) (0.46)\n",
      "Installing collected packages: Pillow\n",
      "  Found existing installation: Pillow 4.2.1\n",
      "    Uninstalling Pillow-4.2.1:\n",
      "      Successfully uninstalled Pillow-4.2.1\n",
      "Successfully installed Pillow-4.1.1\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting image\n",
      "  Downloading https://files.pythonhosted.org/packages/0c/ec/51969468a8b87f631cc0e60a6bf1e5f6eec8ef3fd2ee45dc760d5a93b82a/image-1.5.27-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.5/site-packages (from image) (4.1.1)\n",
      "Collecting django (from image)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/9a/0c028ea0fe4f5803dda1a7afabeed958d0c8b79b0fe762ffbf728db3b90d/Django-2.1.4-py3-none-any.whl (7.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 7.3MB 37kB/s \n",
      "\u001b[?25hRequirement already satisfied: olefile in /opt/conda/lib/python3.5/site-packages (from pillow->image) (0.46)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.5/site-packages (from django->image) (2018.5)\n",
      "Installing collected packages: django, image\n",
      "Successfully installed django-2.1.4 image-1.5.27\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting matplotlib\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/4c/0415f15f96864c3a2242b1c74041a806c100c1b21741206c5d87684437c6/matplotlib-3.0.2-cp35-cp35m-manylinux1_x86_64.whl (12.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 12.9MB 40kB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /opt/conda/lib/python3.5/site-packages (from matplotlib) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.10.0 in /opt/conda/lib/python3.5/site-packages (from matplotlib) (1.14.2)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /opt/conda/lib/python3.5/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.5/site-packages (from matplotlib) (2.1.10)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /opt/conda/lib/python3.5/site-packages (from matplotlib) (2.7.3)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.5/site-packages/setuptools-27.2.0-py3.5.egg (from kiwisolver>=1.0.1->matplotlib) (27.2.0)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/lib/python3.5/site-packages (from cycler>=0.10->matplotlib) (1.11.0)\n",
      "Installing collected packages: matplotlib\n",
      "  Found existing installation: matplotlib 3.0.0\n",
      "    Uninstalling matplotlib-3.0.0:\n",
      "      Successfully uninstalled matplotlib-3.0.0\n",
      "Successfully installed matplotlib-3.0.2\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision --upgrade -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install Pillow==4.1.1\n",
    "!pip install image\n",
    "!pip install matplotlib --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vXjCadon6toa",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import Namespace\n",
    "import collections\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import re\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N518ySE16trp",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set Numpy and PyTorch seeds\n",
    "def set_seeds(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        \n",
    "# Creating directories\n",
    "def create_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PGQLzyss8wja",
    "mdEditEnable": false
   },
   "source": [
    "## 数据\n",
    "\n",
    "我们先来获取一些数据。一个常用的计算机视觉分类数据集是 [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html)。它包含了十种不同类型的图片数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NYy0WlkB9AoK",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-aeec6b20611e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 这里我们只是使用tf来下载数据\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# 这里我们只是使用tf来下载数据\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Ka-WxeEJ8vAd",
    "outputId": "ec24e935-0562-4c55-c2ab-2bfe59a49128",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-81d2135a3b34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 加载数据\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcifar10\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"x:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "X = np.vstack([x_train, x_test])\n",
    "y = np.vstack([y_train, y_test]).squeeze(1)\n",
    "print (\"x:\", X.shape)\n",
    "print (\"y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0YIiwLWcBH07",
    "mdEditEnable": false
   },
   "source": [
    "\n",
    "每张图片的长和宽都是32像素，和三个色彩通道(就是RGB), 我们将它存在一个文件夹里，每种类型的图片都有自己的文件夹，文件夹名就是对应图片的类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xWqzC-M1NCzx",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!rm -rf cifar10_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AdZjOciC-Bzm",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Classes\n",
    "classes = {0: 'plane', 1: 'car', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', \n",
    "           6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DbNtoIxD8dxc",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create image directories\n",
    "data_dir = \"cifar10_data\"\n",
    "os.mkdir(data_dir)\n",
    "for _class in classes.values():\n",
    "    os.mkdir(os.path.join(data_dir, _class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wf5EY4Ey8kFq",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-12fd8b2b8dd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Save images for each class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0m_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"{0:02d}.png\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Save images for each class\n",
    "for i, (image, label) in enumerate(zip(X, y)):\n",
    "    _class = classes[label]\n",
    "    im = Image.fromarray(image)\n",
    "    im.save(os.path.join(data_dir, _class, \"{0:02d}.png\".format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "PrD2oUFu_KVF",
    "outputId": "e336f8c8-5cf5-4235-ec10-68761b6c725c",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.kesci.com/rt_upload/PrD2oUFu_KVF/pk9th77d3.png\">"
      ],
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some samples\n",
    "num_samples = len(classes)\n",
    "for i, _class in enumerate(classes.values()):  \n",
    "    for file in os.listdir(os.path.join(data_dir, _class)):\n",
    "        if file.endswith(\".png\"):\n",
    "            plt.subplot(1, num_samples, i+1)\n",
    "            plt.title(\"{0}\".format(_class))\n",
    "            img = Image.open(os.path.join(data_dir, _class, file))\n",
    "            plt.imshow(img)\n",
    "            plt.axis(\"off\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gVOkpS6O5b-B",
    "mdEditEnable": false
   },
   "source": [
    "## 分类\n",
    "\n",
    "任务是为给出的图片分类，我们会构建一个结构最基础的CNN然后用它处理数据，输出预测的分类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yLW2_1CG2Eyg",
    "mdEditEnable": false
   },
   "source": [
    "### 参数\n",
    "处理图片数据时，不需要保存切分后的文件，我们只会从文件夹中读取他们。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RTMvq5A849-w",
    "outputId": "f9142a73-fbf6-4504-f064-70417c6f8e6d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    seed=1234,\n",
    "    cuda=True,\n",
    "    shuffle=True,\n",
    "    data_dir=\"cifar10_data\",\n",
    "    vectorizer_file=\"vectorizer.json\",\n",
    "    model_state_file=\"model.pth\",\n",
    "    save_dir=\"cifar10_model\",\n",
    "    train_size=0.7,\n",
    "    val_size=0.15,\n",
    "    test_size=0.15,\n",
    "    num_epochs=10,\n",
    "    early_stopping_criteria=5,\n",
    "    learning_rate=1e-3,\n",
    "    batch_size=128,\n",
    "    num_filters=100,\n",
    "    hidden_dim=100,\n",
    "    dropout_p=0.1,\n",
    ")\n",
    "\n",
    "# Set seeds\n",
    "set_seeds(seed=args.seed, cuda=args.cuda)\n",
    "\n",
    "# Create save dir\n",
    "create_dirs(args.save_dir)\n",
    "\n",
    "# Expand filepaths\n",
    "args.vectorizer_file = os.path.join(args.save_dir, args.vectorizer_file)\n",
    "args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n",
    "\n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "print(\"Using CUDA: {}\".format(args.cuda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xaYCCEHOrpGB",
    "mdEditEnable": false
   },
   "source": [
    "### 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8iF6nxgDtOWk",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 将图片转换为Numpy Array\n",
    "def img_to_array(fp):\n",
    "    img = Image.open(fp)\n",
    "    array = np.asarray(img, dtype=\"float32\")\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3VlHdV9r5VzN",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "data = []\n",
    "for i, _class in enumerate(classes.values()):  \n",
    "    for file in os.listdir(os.path.join(data_dir, _class)):\n",
    "        if file.endswith(\".png\"):\n",
    "            full_filepath = os.path.join(data_dir, _class, file)\n",
    "            data.append({\"image\": img_to_array(full_filepath), \"category\": _class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "WvknlOjM5V1z",
    "outputId": "69e2f3bf-42df-4b08-b086-fc744e263db8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plane</td>\n",
       "      <td>[[[105.0, 131.0, 164.0], [106.0, 132.0, 167.0]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plane</td>\n",
       "      <td>[[[156.0, 160.0, 159.0], [156.0, 160.0, 160.0]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plane</td>\n",
       "      <td>[[[91.0, 119.0, 141.0], [91.0, 121.0, 142.0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plane</td>\n",
       "      <td>[[[82.0, 136.0, 186.0], [82.0, 135.0, 184.0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plane</td>\n",
       "      <td>[[[115.0, 165.0, 224.0], [117.0, 167.0, 226.0]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                              image\n",
       "0    plane  [[[105.0, 131.0, 164.0], [106.0, 132.0, 167.0]...\n",
       "1    plane  [[[156.0, 160.0, 159.0], [156.0, 160.0, 160.0]...\n",
       "2    plane  [[[91.0, 119.0, 141.0], [91.0, 121.0, 142.0], ...\n",
       "3    plane  [[[82.0, 136.0, 186.0], [82.0, 135.0, 184.0], ...\n",
       "4    plane  [[[115.0, 165.0, 224.0], [117.0, 167.0, 226.0]..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转化为 Dataframe\n",
    "df = pd.DataFrame(data)\n",
    "print (\"Image shape:\", df.image[0].shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "GXtRpahp5V6p",
    "outputId": "6ea08026-d651-4a75-d40f-94086fb211ce",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: 6000\n",
      "plane: 6000\n",
      "car: 6000\n",
      "deer: 6000\n",
      "truck: 6000\n",
      "frog: 6000\n",
      "ship: 6000\n",
      "dog: 6000\n",
      "bird: 6000\n",
      "horse: 6000\n"
     ]
    }
   ],
   "source": [
    "by_category = collections.defaultdict(list)\n",
    "for _, row in df.iterrows():\n",
    "    by_category[row.category].append(row.to_dict())\n",
    "for category in by_category:\n",
    "    print (\"{0}: {1}\".format(category, len(by_category[category])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AYVNBhLgt-38",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_list = []\n",
    "for _, item_list in sorted(by_category.items()):\n",
    "    if args.shuffle:\n",
    "        np.random.shuffle(item_list)\n",
    "    n = len(item_list)\n",
    "    n_train = int(args.train_size*n)\n",
    "    n_val = int(args.val_size*n)\n",
    "    n_test = int(args.test_size*n)\n",
    "\n",
    "  # 给数据点一个切分属性\n",
    "    for item in item_list[:n_train]:\n",
    "        item['split'] = 'train'\n",
    "    for item in item_list[n_train:n_train+n_val]:\n",
    "        item['split'] = 'val'\n",
    "    for item in item_list[n_train+n_val:]:\n",
    "        item['split'] = 'test'  \n",
    "\n",
    "    # Add to final list\n",
    "    final_list.extend(item_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "o8GNPotNt-6X",
    "outputId": "162a2ddb-db83-4708-b48d-ecbf1d61dd4f",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    42000\n",
       "val       9000\n",
       "test      9000\n",
       "Name: split, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df = pd.DataFrame(final_list)\n",
    "split_df[\"split\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cLdJQPBmX0yJ",
    "mdEditEnable": false
   },
   "source": [
    "### 词汇表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EB-kpxhct-_S",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    def __init__(self, token_to_idx=None):\n",
    "\n",
    "        # Token to index\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self.token_to_idx = token_to_idx\n",
    "\n",
    "        # Index to token\n",
    "        self.idx_to_token = {idx: token \\\n",
    "                             for token, idx in self.token_to_idx.items()}\n",
    "\n",
    "    def to_serializable(self):\n",
    "        return {'token_to_idx': self.token_to_idx}\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        return cls(**contents)\n",
    "\n",
    "    def add_token(self, token):\n",
    "        if token in self.token_to_idx:\n",
    "            index = self.token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self.token_to_idx)\n",
    "            self.token_to_idx[token] = index\n",
    "            self.idx_to_token[index] = token\n",
    "        return index\n",
    "\n",
    "    def add_tokens(self, tokens):\n",
    "        return [self.add_token[token] for token in tokens]\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        return self.token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        if index not in self.idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self.idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "QcpS2G28t_Bv",
    "outputId": "d0f38e9b-311a-42e1-a00a-ca75c8cf672e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Vocabulary(size=10)>\n",
      "10\n",
      "5\n",
      "dog\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary instance\n",
    "category_vocab = Vocabulary()\n",
    "for index, row in df.iterrows():\n",
    "    category_vocab.add_token(row.category)\n",
    "print (category_vocab) # __str__\n",
    "print (len(category_vocab)) # __len__\n",
    "index = category_vocab.lookup_token(\"dog\")\n",
    "print (index)\n",
    "print (category_vocab.lookup_index(index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ubECmrcqZIHI",
    "mdEditEnable": false
   },
   "source": [
    "### 序列化词汇表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "37pGFTBiZIbm",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvWL2JcgZPaw",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class SequenceVocabulary():\n",
    "    def __init__(self, train_means, train_stds):\n",
    "        \n",
    "        self.train_means = train_means\n",
    "        self.train_stds = train_stds\n",
    "        \n",
    "    def to_serializable(self):\n",
    "        contents = {'train_means': self.train_means,\n",
    "                    'train_stds': self.train_stds}\n",
    "        return contents\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, df):\n",
    "        train_data = df[df.split == \"train\"]\n",
    "        means = {0:[], 1:[], 2:[]}\n",
    "        stds = {0:[], 1:[], 2:[]}\n",
    "        for image in train_data.image:\n",
    "            for dim in range(3):\n",
    "                means[dim].append(np.mean(image[:, :, dim]))\n",
    "                stds[dim].append(np.std(image[:, :, dim]))\n",
    "        train_means = np.array((np.mean(means[0]), np.mean(means[1]), \n",
    "                                np.mean(means[2])), dtype=\"float64\").tolist()\n",
    "        train_stds = np.array((np.mean(stds[0]), np.mean(stds[1]), \n",
    "                               np.mean(stds[2])), dtype=\"float64\").tolist()\n",
    "            \n",
    "        return cls(train_means, train_stds)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"<SequenceVocabulary(train_means: {0}, train_stds: {1}>\".format(\n",
    "            self.train_means, self.train_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "-ODlh2wcahqH",
    "outputId": "b165d02a-3b92-40b8-92f5-5055533e6447",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SequenceVocabulary(train_means: [125.40174102783203, 122.99897766113281, 114.00146484375], train_stds: [51.5576171875, 50.800132751464844, 51.22932052612305]>\n"
     ]
    }
   ],
   "source": [
    "# Create SequenceVocabulary instance\n",
    "image_vocab = SequenceVocabulary.from_dataframe(split_df)\n",
    "print (image_vocab) # __str__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lUZKa0c9YD0V",
    "mdEditEnable": false
   },
   "source": [
    "### 向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RyxHZLTFX5VC",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class ImageVectorizer(object):\n",
    "    def __init__(self, image_vocab, category_vocab):\n",
    "        self.image_vocab = image_vocab\n",
    "        self.category_vocab = category_vocab\n",
    "\n",
    "    def vectorize(self, image):\n",
    "        \n",
    "        # Avoid modifying the actual df\n",
    "        image = np.copy(image)\n",
    "        \n",
    "        # Normalize\n",
    "        for dim in range(3):\n",
    "            mean = self.image_vocab.train_means[dim]\n",
    "            std = self.image_vocab.train_stds[dim]\n",
    "            image[:, :, dim] = ((image[:, :, dim] - mean) / std)\n",
    "            \n",
    "        # Reshape frok (32, 32, 3) to (3, 32, 32)\n",
    "        image = np.swapaxes(image, 0, 2)\n",
    "        image = np.swapaxes(image, 1, 2)\n",
    "                \n",
    "        return image\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, df):\n",
    "        \n",
    "        # Create class vocab\n",
    "        category_vocab = Vocabulary()   \n",
    "        for category in sorted(set(df.category)):\n",
    "            category_vocab.add_token(category)\n",
    "            \n",
    "        # Create image vocab\n",
    "        image_vocab = SequenceVocabulary.from_dataframe(df)\n",
    "        \n",
    "        return cls(image_vocab, category_vocab)\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        image_vocab = SequenceVocabulary.from_serializable(contents['image_vocab'])\n",
    "        category_vocab = Vocabulary.from_serializable(contents['category_vocab'])\n",
    "        return cls(image_vocab=image_vocab, \n",
    "                   category_vocab=category_vocab)\n",
    "    \n",
    "    def to_serializable(self):\n",
    "        return {'image_vocab': self.image_vocab.to_serializable(),\n",
    "                'category_vocab': self.category_vocab.to_serializable()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "yXWIhtFUiDUe",
    "outputId": "62f2c017-da89-4333-8cd3-f84abe05723b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SequenceVocabulary(train_means: [125.40174102783203, 122.99897766113281, 114.00146484375], train_stds: [51.5576171875, 50.800132751464844, 51.22932052612305]>\n",
      "<Vocabulary(size=10)>\n",
      "(3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# Vectorizer instance\n",
    "vectorizer = ImageVectorizer.from_dataframe(split_df)\n",
    "print (vectorizer.image_vocab)\n",
    "print (vectorizer.category_vocab)\n",
    "image_vector = vectorizer.vectorize(split_df.iloc[0].image)\n",
    "print (image_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xm7s9RPThF3c",
    "mdEditEnable": false
   },
   "source": [
    "### 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2mL4eEdNX5c1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dzegh16nX5fY",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, vectorizer):\n",
    "        self.df = df\n",
    "        self.vectorizer = vectorizer\n",
    "\n",
    "        # Data splits\n",
    "        self.train_df = self.df[self.df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "        self.val_df = self.df[self.df.split=='val']\n",
    "        self.val_size = len(self.val_df)\n",
    "        self.test_df = self.df[self.df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "        self.lookup_dict = {'train': (self.train_df, self.train_size), \n",
    "                            'val': (self.val_df, self.val_size),\n",
    "                            'test': (self.test_df, self.test_size)}\n",
    "        self.set_split('train')\n",
    "\n",
    "        # Class weights (for imbalances)\n",
    "        class_counts = df.category.value_counts().to_dict()\n",
    "        def sort_key(item):\n",
    "            return self.vectorizer.category_vocab.lookup_token(item[0])\n",
    "        sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
    "        frequencies = [count for _, count in sorted_counts]\n",
    "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, df):\n",
    "        train_df = df[df.split=='train']\n",
    "        return cls(df, ImageVectorizer.from_dataframe(train_df))\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls, df, vectorizer_filepath):\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(df, vectorizer)\n",
    "\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        with open(vectorizer_filepath) as fp:\n",
    "            return ImageVectorizer.from_serializable(json.load(fp))\n",
    "\n",
    "    def save_vectorizer(self, vectorizer_filepath):\n",
    "        with open(vectorizer_filepath, \"w\") as fp:\n",
    "            json.dump(self.vectorizer.to_serializable(), fp)\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        self.target_split = split\n",
    "        self.target_df, self.target_size = self.lookup_dict[split]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Dataset(split={0}, size={1})\".format(\n",
    "            self.target_split, self.target_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.target_df.iloc[index]\n",
    "        image_vector = self.vectorizer.vectorize(row.image)\n",
    "        category_index = self.vectorizer.category_vocab.lookup_token(row.category)\n",
    "        return {'image': image_vector, \n",
    "                'category': category_index}\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        return len(self) // batch_size\n",
    "\n",
    "    def generate_batches(self, batch_size, shuffle=True, drop_last=True, device=\"cpu\"):\n",
    "        dataloader = DataLoader(dataset=self, batch_size=batch_size, \n",
    "                                shuffle=shuffle, drop_last=drop_last)\n",
    "        for data_dict in dataloader:\n",
    "            out_data_dict = {}\n",
    "            for name, tensor in data_dict.items():\n",
    "                out_data_dict[name] = data_dict[name].to(device)\n",
    "            yield out_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "-sW6otUGX5iA",
    "outputId": "5abb9822-37dd-4680-ba93-f85f79c77296",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Dataset(split=train, size=42000)\n",
      "(3, 32, 32)\n",
      "bird\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002])\n"
     ]
    }
   ],
   "source": [
    "# Dataset instance\n",
    "dataset = ImageDataset.load_dataset_and_make_vectorizer(split_df)\n",
    "print (dataset) # __str__\n",
    "input_ = dataset[10] # __getitem__\n",
    "print (input_['image'].shape)\n",
    "category = input_['category']\n",
    "print (dataset.vectorizer.category_vocab.lookup_index(category))\n",
    "print (dataset.class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SjPHp36i3G_i",
    "mdEditEnable": false
   },
   "source": [
    "### 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bPaf6Dy2X5ko",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RKRPzX1nX5nN",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class ImageModel(nn.Module):\n",
    "    def __init__(self, num_hidden_units, num_classes, dropout_p):\n",
    "        super(ImageModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5) # input_channels:3 , output_channels:10 (aka num filters)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) \n",
    "        self.conv_dropout = nn.Dropout2d(dropout_p)\n",
    "        self.fc1 = nn.Linear(20*5*5, num_hidden_units)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc2 = nn.Linear(num_hidden_units, num_classes)\n",
    "\n",
    "    def forward(self, x, apply_softmax=False):\n",
    "          \n",
    "        # 卷积层和池化\n",
    "        z = self.conv1(x) # (N, 10, 28, 28)\n",
    "        z = F.max_pool2d(z, 2) # (N, 10, 14, 14)\n",
    "        z = F.relu(z)\n",
    "        \n",
    "        # 卷积层和池化\n",
    "        z = self.conv2(z) # (N, 20, 10, 10)\n",
    "        z = self.conv_dropout(z) \n",
    "        z = F.max_pool2d(z, 2) # (N, 20, 5, 5)\n",
    "        z = F.relu(z)\n",
    "        \n",
    "        # 整平操作\n",
    "        z = z.view(-1, 20*5*5)\n",
    "        \n",
    "        # 全连接层\n",
    "        z = F.relu(self.fc1(z))\n",
    "        z = self.dropout(z)\n",
    "        y_pred = self.fc2(z)\n",
    "        \n",
    "        if apply_softmax:\n",
    "            y_pred = F.softmax(y_pred, dim=1)\n",
    "        return y_pred \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jAiIbY9TBGef",
    "mdEditEnable": false
   },
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bnMvjt9JX5p4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o0bR1rzqX5sg",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, dataset, model, model_state_file, save_dir, device, \n",
    "                 shuffle, num_epochs, batch_size, learning_rate, \n",
    "                 early_stopping_criteria):\n",
    "        self.dataset = dataset\n",
    "        self.class_weights = dataset.class_weights.to(device)\n",
    "        self.device = device\n",
    "        self.model = model.to(device)\n",
    "        self.save_dir = save_dir\n",
    "        self.device = device\n",
    "        self.shuffle = shuffle\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.loss_func = nn.CrossEntropyLoss(self.class_weights)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer=self.optimizer, mode='min', factor=0.5, patience=1)\n",
    "        self.train_state = {\n",
    "            'stop_early': False, \n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'early_stopping_criteria': early_stopping_criteria,\n",
    "            'learning_rate': learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': model_state_file}\n",
    "    \n",
    "    def update_train_state(self):\n",
    "\n",
    "        # Verbose\n",
    "        print (\"[EPOCH]: {0:02d} | [LR]: {1} | [TRAIN LOSS]: {2:.2f} | [TRAIN ACC]: {3:.1f}% | [VAL LOSS]: {4:.2f} | [VAL ACC]: {5:.1f}%\".format(\n",
    "          self.train_state['epoch_index'], self.train_state['learning_rate'], \n",
    "            self.train_state['train_loss'][-1], self.train_state['train_acc'][-1], \n",
    "            self.train_state['val_loss'][-1], self.train_state['val_acc'][-1]))\n",
    "\n",
    "        # Save one model at least\n",
    "        if self.train_state['epoch_index'] == 0:\n",
    "            torch.save(self.model.state_dict(), self.train_state['model_filename'])\n",
    "            self.train_state['stop_early'] = False\n",
    "\n",
    "        # Save model if performance improved\n",
    "        elif self.train_state['epoch_index'] >= 1:\n",
    "            loss_tm1, loss_t = self.train_state['val_loss'][-2:]\n",
    "\n",
    "            # If loss worsened\n",
    "            if loss_t >= self.train_state['early_stopping_best_val']:\n",
    "                # Update step\n",
    "                self.train_state['early_stopping_step'] += 1\n",
    "\n",
    "            # Loss decreased\n",
    "            else:\n",
    "                # Save the best model\n",
    "                if loss_t < self.train_state['early_stopping_best_val']:\n",
    "                    torch.save(self.model.state_dict(), self.train_state['model_filename'])\n",
    "\n",
    "                # Reset early stopping step\n",
    "                self.train_state['early_stopping_step'] = 0\n",
    "\n",
    "            # Stop early ?\n",
    "            self.train_state['stop_early'] = self.train_state['early_stopping_step'] \\\n",
    "              >= self.train_state['early_stopping_criteria']\n",
    "        return self.train_state\n",
    "  \n",
    "    def compute_accuracy(self, y_pred, y_target):\n",
    "        _, y_pred_indices = y_pred.max(dim=1)\n",
    "        n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "        return n_correct / len(y_pred_indices) * 100\n",
    "  \n",
    "    def run_train_loop(self):\n",
    "        for epoch_index in range(self.num_epochs):\n",
    "            self.train_state['epoch_index'] = epoch_index\n",
    "      \n",
    "            # Iterate over train dataset\n",
    "\n",
    "            # initialize batch generator, set loss and acc to 0, set train mode on\n",
    "            self.dataset.set_split('train')\n",
    "            batch_generator = self.dataset.generate_batches(\n",
    "                batch_size=self.batch_size, shuffle=self.shuffle, \n",
    "                device=self.device)\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "            self.model.train()\n",
    "\n",
    "            for batch_index, batch_dict in enumerate(batch_generator):\n",
    "                # zero the gradients\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                # compute the output\n",
    "                y_pred = self.model(x=batch_dict['image'])\n",
    "                \n",
    "                # compute the loss\n",
    "                loss = self.loss_func(y_pred, batch_dict['category'])\n",
    "                loss_t = loss.item()\n",
    "                running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "                # compute gradients using loss\n",
    "                loss.backward()\n",
    "\n",
    "                # use optimizer to take a gradient step\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                # compute the accuracy\n",
    "                acc_t = self.compute_accuracy(y_pred, batch_dict['category'])\n",
    "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            self.train_state['train_loss'].append(running_loss)\n",
    "            self.train_state['train_acc'].append(running_acc)\n",
    "\n",
    "            # Iterate over val dataset\n",
    "\n",
    "            # initialize batch generator, set loss and acc to 0, set eval mode on\n",
    "            self.dataset.set_split('val')\n",
    "            batch_generator = self.dataset.generate_batches(\n",
    "                batch_size=self.batch_size, shuffle=self.shuffle, device=self.device)\n",
    "            running_loss = 0.\n",
    "            running_acc = 0.\n",
    "            self.model.eval()\n",
    "\n",
    "            for batch_index, batch_dict in enumerate(batch_generator):\n",
    "\n",
    "                # compute the output\n",
    "                y_pred = self.model(x=batch_dict['image'])\n",
    "\n",
    "                # compute the loss\n",
    "                loss = self.loss_func(y_pred, batch_dict['category'])\n",
    "                loss_t = loss.to(\"cpu\").item()\n",
    "                running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "                # compute the accuracy\n",
    "                acc_t = self.compute_accuracy(y_pred, batch_dict['category'])\n",
    "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            self.train_state['val_loss'].append(running_loss)\n",
    "            self.train_state['val_acc'].append(running_acc)\n",
    "\n",
    "            self.train_state = self.update_train_state()\n",
    "            self.scheduler.step(self.train_state['val_loss'][-1])\n",
    "            if self.train_state['stop_early']:\n",
    "                break\n",
    "          \n",
    "    def run_test_loop(self):\n",
    "        # initialize batch generator, set loss and acc to 0, set eval mode on\n",
    "        self.dataset.set_split('test')\n",
    "        batch_generator = self.dataset.generate_batches(\n",
    "            batch_size=self.batch_size, shuffle=self.shuffle, device=self.device)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        self.model.eval()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # compute the output\n",
    "            y_pred = self.model(x=batch_dict['image'])\n",
    "\n",
    "            # compute the loss\n",
    "            loss = self.loss_func(y_pred, batch_dict['category'])\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # compute the accuracy\n",
    "            acc_t = self.compute_accuracy(y_pred, batch_dict['category'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "        self.train_state['test_loss'] = running_loss\n",
    "        self.train_state['test_acc'] = running_acc\n",
    "    \n",
    "    def plot_performance(self):\n",
    "        # Figure size\n",
    "        plt.figure(figsize=(15,5))\n",
    "\n",
    "        # Plot Loss\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(\"Loss\")\n",
    "        plt.plot(trainer.train_state[\"train_loss\"], label=\"train\")\n",
    "        plt.plot(trainer.train_state[\"val_loss\"], label=\"val\")\n",
    "        plt.legend(loc='upper right')\n",
    "\n",
    "        # Plot Accuracy\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(\"Accuracy\")\n",
    "        plt.plot(trainer.train_state[\"train_acc\"], label=\"train\")\n",
    "        plt.plot(trainer.train_state[\"val_acc\"], label=\"val\")\n",
    "        plt.legend(loc='lower right')\n",
    "\n",
    "        # Save figure\n",
    "        plt.savefig(os.path.join(self.save_dir, \"performance.png\"))\n",
    "\n",
    "        # Show plots\n",
    "        plt.show()\n",
    "    \n",
    "    def save_train_state(self):\n",
    "        with open(os.path.join(self.save_dir, \"train_state.json\"), \"w\") as fp:\n",
    "            json.dump(self.train_state, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "Ug60AELzX5vT",
    "outputId": "74f5b9db-ebc0-47d5-e496-afabe9c0ca7b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_modules of ImageModel(\n",
      "  (conv1): Conv2d(3, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv_dropout): Dropout2d(p=0.1)\n",
      "  (fc1): Linear(in_features=500, out_features=100, bias=True)\n",
      "  (dropout): Dropout(p=0.1)\n",
      "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "dataset = ImageDataset.load_dataset_and_make_vectorizer(split_df)\n",
    "dataset.save_vectorizer(args.vectorizer_file)\n",
    "vectorizer = dataset.vectorizer\n",
    "model = ImageModel(num_hidden_units=args.hidden_dim, \n",
    "                   num_classes=len(vectorizer.category_vocab),\n",
    "                   dropout_p=args.dropout_p)\n",
    "print (model.named_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vF9kAEXEX5a4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH]: 00 | [LR]: 0.001 | [TRAIN LOSS]: 1.69 | [TRAIN ACC]: 38.6% | [VAL LOSS]: 1.47 | [VAL ACC]: 47.0%\n",
      "[EPOCH]: 01 | [LR]: 0.001 | [TRAIN LOSS]: 1.39 | [TRAIN ACC]: 50.1% | [VAL LOSS]: 1.29 | [VAL ACC]: 53.9%\n",
      "[EPOCH]: 02 | [LR]: 0.001 | [TRAIN LOSS]: 1.27 | [TRAIN ACC]: 54.9% | [VAL LOSS]: 1.19 | [VAL ACC]: 57.3%\n",
      "[EPOCH]: 03 | [LR]: 0.001 | [TRAIN LOSS]: 1.19 | [TRAIN ACC]: 57.7% | [VAL LOSS]: 1.13 | [VAL ACC]: 60.7%\n",
      "[EPOCH]: 04 | [LR]: 0.001 | [TRAIN LOSS]: 1.13 | [TRAIN ACC]: 60.0% | [VAL LOSS]: 1.11 | [VAL ACC]: 61.2%\n",
      "[EPOCH]: 05 | [LR]: 0.001 | [TRAIN LOSS]: 1.08 | [TRAIN ACC]: 61.6% | [VAL LOSS]: 1.07 | [VAL ACC]: 62.5%\n",
      "[EPOCH]: 06 | [LR]: 0.001 | [TRAIN LOSS]: 1.04 | [TRAIN ACC]: 63.2% | [VAL LOSS]: 1.06 | [VAL ACC]: 62.3%\n",
      "[EPOCH]: 07 | [LR]: 0.001 | [TRAIN LOSS]: 1.02 | [TRAIN ACC]: 64.2% | [VAL LOSS]: 1.02 | [VAL ACC]: 63.8%\n",
      "[EPOCH]: 08 | [LR]: 0.001 | [TRAIN LOSS]: 0.99 | [TRAIN ACC]: 65.5% | [VAL LOSS]: 1.01 | [VAL ACC]: 64.6%\n",
      "[EPOCH]: 09 | [LR]: 0.001 | [TRAIN LOSS]: 0.96 | [TRAIN ACC]: 66.3% | [VAL LOSS]: 0.99 | [VAL ACC]: 65.4%\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "trainer = Trainer(dataset=dataset, model=model, \n",
    "                  model_state_file=args.model_state_file, \n",
    "                  save_dir=args.save_dir, device=args.device,\n",
    "                  shuffle=args.shuffle, num_epochs=args.num_epochs, \n",
    "                  batch_size=args.batch_size, learning_rate=args.learning_rate, \n",
    "                  early_stopping_criteria=args.early_stopping_criteria)\n",
    "trainer.run_train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "colab_type": "code",
    "id": "2G6I5YWtt_Ea",
    "outputId": "0ca459c6-0053-4a43-82a3-6a1e1c6e5c33",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.kesci.com/rt_upload/2G6I5YWtt_Ea/pk9tmpf0y1.png\">"
      ],
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot performance\n",
    "trainer.plot_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Iz3G5eaTS04m",
    "outputId": "9d3a0b4e-59d3-4fcd-860f-f0a062c4e8e9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.98\n",
      "Test Accuracy: 66.3%\n"
     ]
    }
   ],
   "source": [
    "# Test performance\n",
    "trainer.run_test_loop()\n",
    "print(\"Test loss: {0:.2f}\".format(trainer.train_state['test_loss']))\n",
    "print(\"Test Accuracy: {0:.1f}%\".format(trainer.train_state['test_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kqMzljfpS09F",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save all results\n",
    "trainer.save_train_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1fMNOVJUYvhs",
    "mdEditEnable": false
   },
   "source": [
    "\n",
    "66% 左右的测试性能在 Cifar10 数据集上并不差，但是我们可以做的更好。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EclYytw6Swh-",
    "mdEditEnable": false
   },
   "source": [
    "## Transfer learning\n",
    "## 迁移学习\n",
    "\n",
    "这一节里，我们即将使用在很多数据集上的性能都非常好的训练好的模型。我们会直接使用它的构架和权重来初始化模型，并用它训练。我们就冻结初始的卷积权重，然后调整后面的卷积和全连接层。\n",
    " \n",
    "迁移学习之所以适用于这个场景，是因为最初的卷积层在处理图片中包含(不管他的类别是什么)的空间信息时表现十分优异。我们会用这些巨大的已训练好模型的特征提取器用在自己的数据集上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mxl4PEfqTMwm",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "GjufXPDJTB7W",
    "outputId": "709a1c26-7c67-420f-83be-bdf5409cf4cc",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alexnet', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'inception_v3', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn']\n"
     ]
    }
   ],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "print (model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1173
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "daJN4BSWS016",
    "outputId": "0608949f-b8ec-471e-c32b-04079b8980b9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\" to /home/kesci/.torch/models/vgg19_bn-c79401a0.pth\n",
      "100%|██████████| 574769405/574769405 [00:42<00:00, 13614017.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_parameters of VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace)\n",
      "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (25): ReLU(inplace)\n",
      "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace)\n",
      "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): ReLU(inplace)\n",
      "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): ReLU(inplace)\n",
      "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace)\n",
      "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (45): ReLU(inplace)\n",
      "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (48): ReLU(inplace)\n",
      "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (51): ReLU(inplace)\n",
      "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "model_name = 'vgg19_bn'\n",
    "vgg_19bn = models.__dict__[model_name](pretrained=True) # Set false to train from scratch\n",
    "print (vgg_19bn.named_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XBudDGFz1j87",
    "mdEditEnable": false
   },
   "source": [
    "我们选择的 VGG模型 包含了 特征--`features` 和 分类器--`classifier`两个组件。`features`组件由卷积层和池化层组成，作为特征提取器。而 `classifier`组件由全连接层组成。我们将会冻结 `feature`组件绝大多的权重，然后为了CIFAR10分类任务自己设计全连接层。如果你想直接使用VGG而不是稍作修改，你可以在本地的 `/usr/local/lib/python3.X/dist-packages/torchvision/models` 访问默认的模型。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YmzQIXsd59Rj",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class ImageModel(nn.Module):\n",
    "    def __init__(self, feature_extractor, num_hidden_units, \n",
    "                 num_classes, dropout_p):\n",
    "        super(ImageModel, self).__init__()\n",
    "        \n",
    "        # 训练好的特征提取器\n",
    "        self.feature_extractor = feature_extractor\n",
    "        \n",
    "        # 全连接层权重\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 250, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(250, 100, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(100, 10, bias=True),\n",
    "            )\n",
    "\n",
    "    def forward(self, x, apply_softmax=False):\n",
    "          \n",
    "        # 特征提取器\n",
    "        z = self.feature_extractor(x)\n",
    "        z = z.view(x.size(0), -1)\n",
    "        \n",
    "        # FC\n",
    "        y_pred = self.classifier(z)\n",
    "\n",
    "        if apply_softmax:\n",
    "            y_pred = F.softmax(y_pred, dim=1)\n",
    "        return y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1139
    },
    "colab_type": "code",
    "id": "czo1bGBwXKNj",
    "outputId": "9d407e14-2415-41ba-9f20-37e33f8ab716",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_parameters of ImageModel(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace)\n",
      "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (25): ReLU(inplace)\n",
      "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace)\n",
      "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): ReLU(inplace)\n",
      "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): ReLU(inplace)\n",
      "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace)\n",
      "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (45): ReLU(inplace)\n",
      "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (48): ReLU(inplace)\n",
      "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (51): ReLU(inplace)\n",
      "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=250, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=250, out_features=100, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "dataset = ImageDataset.load_dataset_and_make_vectorizer(split_df)\n",
    "dataset.save_vectorizer(args.vectorizer_file)\n",
    "vectorizer = dataset.vectorizer\n",
    "model = ImageModel(feature_extractor=vgg_19bn.features, \n",
    "                   num_hidden_units=args.hidden_dim,\n",
    "                   num_classes=len(vectorizer.category_vocab), \n",
    "                   dropout_p=args.dropout_p)\n",
    "print (model.named_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hZybxGHoDTwQ",
    "mdEditEnable": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 微调最后几层卷积层和全连接层\n",
    "for i, param in enumerate(model.feature_extractor.parameters()):\n",
    "    if i < 36:\n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GTbYKussTvB2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH]: 00 | [LR]: 0.001 | [TRAIN LOSS]: 0.93 | [TRAIN ACC]: 71.7% | [VAL LOSS]: 0.60 | [VAL ACC]: 80.9%\n",
      "[EPOCH]: 01 | [LR]: 0.001 | [TRAIN LOSS]: 0.57 | [TRAIN ACC]: 83.1% | [VAL LOSS]: 0.55 | [VAL ACC]: 83.3%\n",
      "[EPOCH]: 02 | [LR]: 0.001 | [TRAIN LOSS]: 0.42 | [TRAIN ACC]: 87.7% | [VAL LOSS]: 0.55 | [VAL ACC]: 84.0%\n",
      "[EPOCH]: 03 | [LR]: 0.001 | [TRAIN LOSS]: 0.33 | [TRAIN ACC]: 90.5% | [VAL LOSS]: 0.54 | [VAL ACC]: 84.7%\n",
      "[EPOCH]: 04 | [LR]: 0.001 | [TRAIN LOSS]: 0.26 | [TRAIN ACC]: 92.7% | [VAL LOSS]: 0.53 | [VAL ACC]: 84.7%\n",
      "[EPOCH]: 05 | [LR]: 0.001 | [TRAIN LOSS]: 0.19 | [TRAIN ACC]: 94.7% | [VAL LOSS]: 0.58 | [VAL ACC]: 85.0%\n",
      "[EPOCH]: 06 | [LR]: 0.001 | [TRAIN LOSS]: 0.15 | [TRAIN ACC]: 95.8% | [VAL LOSS]: 0.64 | [VAL ACC]: 85.1%\n",
      "[EPOCH]: 07 | [LR]: 0.001 | [TRAIN LOSS]: 0.08 | [TRAIN ACC]: 97.9% | [VAL LOSS]: 0.60 | [VAL ACC]: 86.6%\n",
      "[EPOCH]: 08 | [LR]: 0.001 | [TRAIN LOSS]: 0.04 | [TRAIN ACC]: 98.9% | [VAL LOSS]: 0.72 | [VAL ACC]: 86.5%\n",
      "[EPOCH]: 09 | [LR]: 0.001 | [TRAIN LOSS]: 0.03 | [TRAIN ACC]: 99.3% | [VAL LOSS]: 0.72 | [VAL ACC]: 87.4%\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "trainer = Trainer(dataset=dataset, model=model, \n",
    "                  model_state_file=args.model_state_file, \n",
    "                  save_dir=args.save_dir, device=args.device,\n",
    "                  shuffle=args.shuffle, num_epochs=args.num_epochs, \n",
    "                  batch_size=args.batch_size, learning_rate=args.learning_rate, \n",
    "                  early_stopping_criteria=args.early_stopping_criteria)\n",
    "trainer.run_train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "colab_type": "code",
    "id": "NCLCnQgATvMj",
    "outputId": "20bca437-868c-41c3-c95c-4b328c9024fc",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.kesci.com/rt_upload/NCLCnQgATvMj/pk9v2jlvp3.png\">"
      ],
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot performance\n",
    "trainer.plot_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Hjn0HJVoTvJ0",
    "outputId": "789735eb-61fc-4745-e133-c161f9d6fec9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.72\n",
      "Test Accuracy: 87.2%\n"
     ]
    }
   ],
   "source": [
    "# Test performance\n",
    "trainer.run_test_loop()\n",
    "print(\"Test loss: {0:.2f}\".format(trainer.train_state['test_loss']))\n",
    "print(\"Test Accuracy: {0:.1f}%\".format(trainer.train_state['test_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZQVrGTNNTvH0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save all results\n",
    "trainer.save_train_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7CL689FebJhf",
    "mdEditEnable": false
   },
   "source": [
    "性能好了太多了！如果训练时间足够的话，最高可以达到 95% 的准确率 :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "02iDXCtiYo5K",
    "mdEditEnable": false
   },
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cVT--tAvnOu7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 1, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1qQjnXpnYoMM",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Inference(object):\n",
    "    def __init__(self, model, vectorizer):\n",
    "        self.model = model\n",
    "        self.model.to(\"cpu\")\n",
    "        self.vectorizer = vectorizer\n",
    "  \n",
    "    def predict_category(self, image):\n",
    "        # Vectorize\n",
    "        image_vector = self.vectorizer.vectorize(image)\n",
    "        image_vector = torch.tensor(image_vector).unsqueeze(0)\n",
    "        \n",
    "        # Forward pass\n",
    "        self.model.eval()\n",
    "        y_pred = self.model(x=image_vector, apply_softmax=True)\n",
    "\n",
    "        # Top category\n",
    "        y_prob, indices = y_pred.max(dim=1)\n",
    "        index = indices.item()\n",
    "\n",
    "        # Predicted category\n",
    "        category = vectorizer.category_vocab.lookup_index(index)\n",
    "        probability = y_prob.item()\n",
    "        return {'category': category, 'probability': probability}\n",
    "    \n",
    "    def predict_top_k(self, image, k):\n",
    "        # Vectorize\n",
    "        image_vector = self.vectorizer.vectorize(image)\n",
    "        image_vector = torch.tensor(image_vector).unsqueeze(0)\n",
    "        \n",
    "        # Forward pass\n",
    "        self.model.eval()\n",
    "        y_pred = self.model(x=image_vector, apply_softmax=True)\n",
    "        \n",
    "        # Top k categories\n",
    "        y_prob, indices = torch.topk(y_pred, k=k)\n",
    "        probabilities = y_prob.detach().numpy()[0]\n",
    "        indices = indices.detach().numpy()[0]\n",
    "\n",
    "        # Results\n",
    "        results = []\n",
    "        for probability, index in zip(probabilities, indices):\n",
    "            category = self.vectorizer.category_vocab.lookup_index(index)\n",
    "            results.append({'category': category, 'probability': probability})\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MbTRzW8CYoWc",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get a sample\n",
    "sample = split_df[split_df.split==\"test\"].iloc[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "DswQ0pikYoR_",
    "outputId": "dedeef0c-be8e-4015-b401-7bb57080a641",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: car\n",
      "(car → p=1.00)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.kesci.com/rt_upload/DswQ0pikYoR_/pk9w20dzat.png\">"
      ],
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inference\n",
    "inference = Inference(model=model, vectorizer=vectorizer)\n",
    "prediction = inference.predict_category(sample.image)\n",
    "print (\"Actual:\", sample.category)\n",
    "test_image = np.array(sample.image, dtype='uint8')\n",
    "plt.imshow(test_image)\n",
    "plt.axis(\"off\")\n",
    "print(\"({} → p={:0.2f})\".format(prediction['category'], \n",
    "                                prediction['probability']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "72_-iRQxYoQK",
    "outputId": "7a65b46b-fc51-4b24-eba1-d2a404af6e91",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: car\n",
      "car → (p=1.00)\n",
      "truck → (p=0.00)\n",
      "ship → (p=0.00)\n",
      "plane → (p=0.00)\n",
      "frog → (p=0.00)\n",
      "dog → (p=0.00)\n",
      "cat → (p=0.00)\n",
      "bird → (p=0.00)\n",
      "deer → (p=0.00)\n",
      "horse → (p=0.00)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.kesci.com/rt_upload/72_-iRQxYoQK/pk9w2gbl3o.png\">"
      ],
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Top-k inference\n",
    "top_k = inference.predict_top_k(sample.image, k=len(vectorizer.category_vocab))\n",
    "print (\"Actual:\", sample.category)\n",
    "plt.imshow(test_image)\n",
    "plt.axis(\"off\")\n",
    "for result in top_k:\n",
    "    print (\"{} → (p={:0.2f})\".format(result['category'], \n",
    "                                     result['probability']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CFD1E5865019468F8ED5A055B1461D2C"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
